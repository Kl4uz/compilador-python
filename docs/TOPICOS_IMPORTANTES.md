# üìã T√≥picos Importantes para Funcionamento do Compilador

---

## üéØ Resumo Executivo

O compilador √© composto por **7 fases principais** que trabalham de forma integrada. Cada fase tem responsabilidades claras:

| Fase | Arquivo | Fun√ß√£o | Status |
|------|---------|--------|--------|
| 1Ô∏è‚É£ **L√©xico** | `lexer.py` | Tokeniza√ß√£o | ‚úÖ Completo |
| 2Ô∏è‚É£ **Sint√°tico** | `parser.py` | Parse LL(1) | ‚úÖ Completo |
| 3Ô∏è‚É£ **AST** | `ast/ast_builder.py` | √Årvore Sint√°tica | ‚úÖ Completo |
| 4Ô∏è‚É£ **Sem√¢ntica** | `ast/analyzer.py` | An√°lise Sem√¢ntica | ‚úÖ Completo |
| 5Ô∏è‚É£ **IR** | `ir/ir_generator.py` | TAC + Qu√°druplas | ‚úÖ Completo |
| 6Ô∏è‚É£ **Otimiza√ß√£o** | `optimizer/optimizer.py` | Otimiza√ß√µes | ‚úÖ Completo |
| 7Ô∏è‚É£ **Assembly** | `codegen/assembly.py` | Gera√ß√£o Assembly | ‚úÖ Completo |

---

# üìç T√ìPICOS PRINCIPAIS

## 1Ô∏è‚É£ **LEXER (An√°lise L√©xica)**

### üìÅ Arquivo Principal
- **`compiler/lexer.py`** ‚Äî 76 linhas

### üéØ Objetivo
Converter texto bruto em **tokens** (unidades l√©xicas)

### üîß O que faz

```python
# ENTRADA: "int x = 5 + 3;"
# SA√çDA: [INT, ID('x'), EQUALS, NUMBER(5), PLUS, NUMBER(3), SEMICOLON]
```

### üìã Componentes Principais

#### 1. **Tokens Definidos** (21 tipos)
```python
tokens = (
    'ID', 'NUMBER',                              # Identificadores e n√∫meros
    'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'EQUALS',  # Operadores
    'LT', 'GT', 'LE', 'GE', 'EQ', 'NE',        # Comparadores
    'LPAREN', 'RPAREN', 'LBRACE', 'RBRACE',     # Delimitadores
    'SEMICOLON', 'COMMA',                        # Pontua√ß√£o
)
```

#### 2. **Palavras Reservadas** (7 palavras-chave)
```python
reserved = {
    'if': 'IF',
    'else': 'ELSE', 
    'while': 'WHILE',
    'for': 'FOR',
    'return': 'RETURN',
    'int': 'INT',
    'print': 'PRINT'
}
```

#### 3. **Regras L√©xicas** (Regex)
```python
# Tokens simples (1 caractere)
t_PLUS = r'\+'
t_MINUS = r'-'
t_TIMES = r'\*'
t_DIVIDE = r'/'
t_EQUALS = r'='
...

# Identificadores e palavras-chave
def t_ID(t):
    r'[a-zA-Z_][a-zA-Z0-9_]*'
    t.type = reserved.get(t.value, 'ID')  # Verifica se √© palavra-chave
    return t

# N√∫meros (inteiros)
def t_NUMBER(t):
    r'\d+'
    t.value = int(t.value)
    return t

# Quebras de linha (rastreamento)
def t_newline(t):
    r'\n+'
    t.lexer.lineno += len(t.value)

# Ignora espa√ßos
t_ignore = ' \t'

# Tratamento de erros
def t_error(t):
    print(f"[ERRO L√âXICO] Caractere ilegal '{t.value[0]}'")
    t.lexer.skip(1)
```

#### 4. **Fun√ß√£o Principal**
```python
def tokenize(source_code):
    """Retorna lista de tokens do c√≥digo-fonte"""
    local_lexer = lex.lex()
    local_lexer.input(source_code)
    return list(local_lexer)
```

### üîç Exemplo Real

```
ENTRADA:        "int x = 5;"
                 ‚Üì
TOKENIZA√á√ÉO:    [INT, ID('x'), EQUALS, NUMBER(5), SEMICOLON]
                 ‚Üì
SA√çDA:          [
                  Token(INT, 'int', 1),
                  Token(ID, 'x', 1),
                  Token(EQUALS, '=', 1),
                  Token(NUMBER, 5, 1),
                  Token(SEMICOLON, ';', 1)
                ]
```

### ‚öôÔ∏è Depend√™ncia Externa
- **PLY (Python Lex-Yacc)** ‚Äî biblioteca de lexing autom√°tico

---

## 2Ô∏è‚É£ **PARSER (An√°lise Sint√°tica)**

### üìÅ Arquivo Principal
- **`compiler/parser.py`** ‚Äî 358 linhas

### üéØ Objetivo
Converter tokens em **√°rvore sint√°tica** (Parse Tree)

### üîß Tipo de Parser
- **LL(1) Top-Down** ‚Äî Recursive Descent com lookahead de 1 token
- **N√£o-amb√≠guo** ‚Äî Uma √∫nica forma de parser

### üìã Estrutura do Parser

#### 1. **Classe Principal**
```python
class LL1Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0                    # Position no stream
        self.current_token = tokens[0]  # Token atual
        self.errors = []                # Erros encontrados
```

#### 2. **M√©todos Essenciais**
```python
def match(self, expected_type):
    """Verifica e consome um token esperado"""
    if self.current_token.type == expected_type:
        token = self.current_token
        self.advance()
        return token
    else:
        self.error(f"Esperado {expected_type}")
        return None

def peek(self):
    """Olha 1 token √† frente sem consumir"""
    return self.current_token.type

def advance(self):
    """Avan√ßa para pr√≥ximo token"""
    self.pos += 1
    if self.pos < len(self.tokens):
        self.current_token = self.tokens[self.pos]
```

#### 3. **Fun√ß√µes de Parsing** (Um m√©todo por n√£o-terminal)

```python
# PROGRAMA ‚Üí DECLARA√á√ÉO*
def program(self):
    declarations = self.declaration_list()
    return ('program', declarations)

# DECLARA√á√ÉO ‚Üí FUN√á√ÉO | STATEMENT
def declaration(self):
    if self.peek() == 'INT':
        # Tenta diferenciar fun√ß√£o vs atribui√ß√£o
        if eh_funcao():
            return self.function_declaration()
        else:
            return self.statement()

# FUN√á√ÉO ‚Üí INT ID ( PARAMS ) { STATEMENTS }
def function_declaration(self):
    self.match('INT')
    name = self.match('ID').value
    self.match('LPAREN')
    params = self.parameter_list() if self.peek() != 'RPAREN' else []
    self.match('RPAREN')
    self.match('LBRACE')
    body = self.statement_list()
    self.match('RBRACE')
    return ('function', name, params, body)

# EXPRESS√ÉO ‚Üí COMPARA√á√ÉO
def expression(self):
    return self.comparison()

# COMPARA√á√ÉO ‚Üí TERMO ((< | > | <= | >=) TERMO)*
def comparison(self):
    left = self.term()
    while self.peek() in ['LT', 'GT', 'LE', 'GE', 'EQ', 'NE']:
        op = self.current_token.type
        self.advance()
        right = self.term()
        left = (op, left, right)  # Node bin√°rio
    return left

# TERMO ‚Üí FATOR ((+ | -) FATOR)*
def term(self):
    left = self.factor()
    while self.peek() in ['PLUS', 'MINUS']:
        op = self.current_token.value
        self.advance()
        right = self.factor()
        left = (op, left, right)  # Node bin√°rio
    return left

# FATOR ‚Üí N√öMERO | ID | EXPRESS√ÉO_PAR√äNTESES
def factor(self):
    if self.peek() == 'NUMBER':
        return self.match('NUMBER').value
    elif self.peek() == 'ID':
        return self.match('ID').value
    elif self.peek() == 'LPAREN':
        self.advance()
        expr = self.expression()
        self.match('RPAREN')
        return expr
```

#### 4. **Gram√°tica BNF Impl√≠cita**

```
program        ‚Üí declaration_list
declaration_list ‚Üí declaration*
declaration    ‚Üí function_declaration | statement

function_declaration 
               ‚Üí INT ID LPAREN parameter_list? RPAREN LBRACE statement_list RBRACE

parameter_list ‚Üí parameter (COMMA parameter)*
parameter      ‚Üí INT ID

statement_list ‚Üí statement*
statement      ‚Üí decl_assign | assign | print_stmt | return_stmt | if_stmt | while_stmt | for_stmt

decl_assign    ‚Üí INT ID EQUALS expression SEMICOLON
assign         ‚Üí ID EQUALS expression SEMICOLON
print_stmt     ‚Üí PRINT LPAREN expression RPAREN SEMICOLON
return_stmt    ‚Üí RETURN expression? SEMICOLON

if_stmt        ‚Üí IF LPAREN expression RPAREN LBRACE statement_list RBRACE (ELSE LBRACE statement_list RBRACE)?
while_stmt     ‚Üí WHILE LPAREN expression RPAREN LBRACE statement_list RBRACE
for_stmt       ‚Üí FOR LPAREN statement expression SEMICOLON statement RPAREN LBRACE statement_list RBRACE

expression     ‚Üí comparison
comparison     ‚Üí term ((LT | GT | LE | GE | EQ | NE) term)*
term           ‚Üí factor ((PLUS | MINUS) factor)*
factor         ‚Üí (TIMES | DIVIDE) factor | unary

unary          ‚Üí MINUS unary | primary
primary        ‚Üí NUMBER | ID | LPAREN expression RPAREN
```

### üìä Exemplo Real

```
ENTRADA TOKENS:
  [INT, ID('x'), EQUALS, NUMBER(5), SEMICOLON]

PARSING:
  program()
    ‚Üí declaration_list()
      ‚Üí declaration()
        ‚Üí statement()
          ‚Üí decl_assign()
            ‚Üí match('INT')
            ‚Üí match('ID') ‚Üí 'x'
            ‚Üí match('EQUALS')
            ‚Üí expression() ‚Üí NUMBER(5)
            ‚Üí match('SEMICOLON')

PARSE TREE RETORNADO:
  ('program', [
    ('decl_assign', 'x', 5)
  ])
```

---

## 3Ô∏è‚É£ **AST (√Årvore Sint√°tica Abstrata)**

### üìÅ Arquivos
- **`compiler/ast/ast_builder.py`** ‚Äî Construir AST
- **`compiler/ast/analyzer.py`** ‚Äî An√°lise Sem√¢ntica
- **`compiler/ast/symbol_table.py`** ‚Äî Tabela de S√≠mbolos

### üéØ Objetivo
Transformar Parse Tree em **estrutura sem√¢ntica** mais limpa

### üìã Tipos de N√≥s

```python
class ASTNode:
    """Classe base para todos n√≥s AST"""
    def __init__(self, node_type):
        self.node_type = node_type

class ProgramNode(ASTNode):
    def __init__(self, declarations):
        super().__init__('program')
        self.declarations = declarations

class FunctionNode(ASTNode):
    def __init__(self, name, params, body):
        super().__init__('function')
        self.name = name
        self.params = params
        self.body = body

class DeclAssignNode(ASTNode):
    def __init__(self, name, value):
        super().__init__('decl_assign')
        self.name = name
        self.value = value

class BinOpNode(ASTNode):
    def __init__(self, op, left, right):
        super().__init__('binop')
        self.op = op
        self.left = left
        self.right = right

class IfNode(ASTNode):
    def __init__(self, condition, then_block, else_block=None):
        super().__init__('if')
        self.condition = condition
        self.then_block = then_block
        self.else_block = else_block

class WhileNode(ASTNode):
    def __init__(self, condition, body):
        super().__init__('while')
        self.condition = condition
        self.body = body
```

---

## 4Ô∏è‚É£ **AN√ÅLISE SEM√ÇNTICA**

### üìÅ Arquivo Principal
- **`compiler/ast/analyzer.py`** ‚Äî 164 linhas

### üéØ Objetivo
Validar **tipos, escopos e declara√ß√µes**

### üîß Verifica√ß√µes Realizadas

1. **Verifica√ß√£o de Tipos**
   ```python
   # ‚úÖ Tipo correto
   int x = 5;           # OK
   
   # ‚ùå Tipo incorreto
   int x = "string";    # ERRO
   ```

2. **Verifica√ß√£o de Declara√ß√£o**
   ```python
   # ‚úÖ Vari√°vel declarada
   int x = 5;
   print(x);            # OK
   
   # ‚ùå Vari√°vel n√£o declarada
   print(y);            # ERRO: Vari√°vel 'y' n√£o declarada
   ```

3. **Verifica√ß√£o de Escopo**
   ```python
   int main() {
       int x = 5;       # Escopo global
       if (x > 0) {
           int y = 10;  # Escopo local do if
       }
       print(y);        # ERRO: 'y' n√£o existe neste escopo
   }
   ```

4. **Verifica√ß√£o de Duplicatas**
   ```python
   int x = 5;
   int x = 10;          # ERRO: Vari√°vel 'x' j√° declarada
   ```

5. **Verifica√ß√£o de Return**
   ```python
   int soma(int a, int b) {
       int r = a + b;
       return r;        # OK
   }
   
   int funcao() {
       int x = 5;
       # ERRO: Fun√ß√£o 'funcao' precisa de 'return'
   }
   ```

### üìã Classe Principal

```python
class SemanticAnalyzer:
    def __init__(self):
        self.symbol_table = SymbolTable()
        self.errors = []
        self.current_function = None
    
    def analyze(self, ast_node):
        """Retorna: (sucesso, erros, tabela_s√≠mbolos)"""
        self.errors = []
        self.visit(ast_node)
        return len(self.errors) == 0, self.errors, self.symbol_table
    
    def visit(self, node):
        """Padr√£o Visitor para AST"""
        method_name = f'visit_{node.node_type}'
        visitor = getattr(self, method_name, self.generic_visit)
        return visitor(node)
```

### üìä Tabela de S√≠mbolos

```python
class SymbolTable:
    """Gerencia escopos e s√≠mbolos"""
    def __init__(self):
        self.scopes = [{}]  # Lista de dicts (escopos)
    
    def insert(self, name, var_type, is_param=False):
        """Insere s√≠mbolo no escopo atual"""
        self.scopes[-1][name] = {
            'type': var_type,
            'is_param': is_param,
            'offset': len(self.scopes[-1])
        }
    
    def lookup(self, name):
        """Busca s√≠mbolo em todos escopos"""
        for scope in reversed(self.scopes):
            if name in scope:
                return scope[name]
        return None
    
    def enter_scope(self, name):
        """Entra em novo escopo (fun√ß√£o, bloco)"""
        self.scopes.append({})
    
    def exit_scope(self):
        """Sai do escopo atual"""
        self.scopes.pop()
```

---

## 5Ô∏è‚É£ **IR GENERATOR (Gera√ß√£o de C√≥digo Intermedi√°rio)**

### üìÅ Arquivo Principal
- **`compiler/ir/ir_generator.py`** ‚Äî 202 linhas

### üéØ Objetivo
Converter AST em **Three-Address Code (TAC) / Qu√°druplas**

### üîß M√©todo de Gera√ß√£o

Usa padr√£o **Visitor** para percorrer AST:

```python
class IRGenerator:
    def __init__(self, symbol_table):
        self.ir_program = IRProgram()
        self.temp_counter = 0
        self.label_count = 0
    
    def new_temp(self):
        """Cria vari√°vel tempor√°ria √∫nica"""
        temp = f"t{self.temp_counter}"
        self.temp_counter += 1
        return temp
    
    def new_label(self):
        """Cria label √∫nico"""
        label = f"L{self.label_count}"
        self.label_count += 1
        return label
    
    def emit(self, op, a1=None, a2=None, res=None):
        """Emite qu√°drupla"""
        self.ir_program.emit(op, a1, a2, res)
```

### üìã Visitadores (um por tipo de n√≥)

```python
# OPERA√á√ïES ARITM√âTICAS
def visit_binop(self, node):
    left = self.visit(node.left)
    right = self.visit(node.right)
    temp = self.new_temp()
    self.emit(node.op, left, right, temp)  # (op, left, right, temp)
    return temp

# ATRIBUI√á√ÉO
def visit_assign(self, node):
    val = self.visit(node.value)
    self.emit('assign', val, None, node.name)  # (assign, valor, -, var)

# PRINT
def visit_print(self, node):
    val = self.visit(node.value)
    self.emit('print', val)  # (print, valor, -, -)

# RETORNO
def visit_return(self, node):
    if node.value:
        val = self.visit(node.value)
        self.emit('return', val)  # (return, valor, -, -)

# IF/ELSE
def visit_if(self, node):
    cond = self.visit(node.condition)
    Ltrue = self.new_label()
    Lfalse = self.new_label()
    Lend = self.new_label()
    
    self.emit('IF_GOTO', cond, None, Ltrue)    # (IF_GOTO, cond, -, Ltrue)
    self.emit('GOTO', None, None, Lfalse)      # (GOTO, -, -, Lfalse)
    self.emit('LABEL', None, None, Ltrue)      # (LABEL, -, -, Ltrue)
    # ... corpo ...
    self.emit('LABEL', None, None, Lend)       # (LABEL, -, -, Lend)

# WHILE
def visit_while(self, node):
    Lbegin = self.new_label()
    Lend = self.new_label()
    
    self.emit('LABEL', None, None, Lbegin)     # (LABEL, -, -, Lbegin)
    cond = self.visit(node.condition)
    self.emit('IF_FALSE_GOTO', cond, None, Lend)  # (IF_FALSE_GOTO, cond, -, Lend)
    # ... corpo ...
    self.emit('GOTO', None, None, Lbegin)      # (GOTO, -, -, Lbegin)
    self.emit('LABEL', None, None, Lend)       # (LABEL, -, -, Lend)
```

---

## 6Ô∏è‚É£ **OPTIMIZER (Otimiza√ß√µes)**

### üìÅ Arquivos
- **`compiler/optimizer/optimizer.py`** ‚Äî 237 linhas
- **`compiler/optimizer/peephole.py`** ‚Äî Otimiza√ß√µes aritm√©ticas

### üéØ Objetivo
Reduzir tamanho e melhorar efici√™ncia do c√≥digo intermedi√°rio

### üîß Otimiza√ß√µes Implementadas

| Otimiza√ß√£o | Antes | Depois | Redu√ß√£o |
|-----------|-------|--------|---------|
| **CSE** (Common Subexpression Elimination) | `t1=a+b; t2=a+b` | `t1=a+b; t2=t1` | 1 instr |
| **Constant Folding** | `t0 = 3 * 2` | `t0 = 6` | simplify |
| **Algebraic Simplification** | `t0 = 3 * 2` | `t0 = 3 << 1` | shift otimizado |
| **Dead Code Elimination** | `t1 = a + b; ... (t1 n√£o usado)` | removido | 1 instr |
| **Copy Propagation** | `t1 = x; y = t1` | `y = x` | propaga |
| **Peephole Optimization** | `x * 2` | `x << 1` | mais eficiente |

### üìã Exemplo Real

```
C√ìDIGO ORIGINAL:
  t0 = 3 * 2      ‚Üê Constant Folding
  t1 = 5 + t0
  t2 = t1 - 1
  resultado = t2  ‚Üê Copy Propagation
  print resultado
  return 0

AP√ìS CONSTANT FOLDING:
  t0 = 6
  t1 = 5 + 6
  t2 = t1 - 1
  resultado = t2
  print resultado
  return 0

AP√ìS COPY PROPAGATION:
  t1 = 5 + 6
  t2 = t1 - 1
  resultado = t2
  print resultado
  return 0

AP√ìS CONSTANT FOLDING (novamente):
  resultado = 10
  print resultado
  return 0

REDU√á√ÉO: 7 ‚Üí 3 instru√ß√µes (57% redu√ß√£o!)
```

---

## 7Ô∏è‚É£ **CODEGEN (Gera√ß√£o de Assembly)**

### üìÅ Arquivos
- **`compiler/codegen/codegen.py`** ‚Äî Coordenador
- **`compiler/codegen/assembly.py`** ‚Äî Gerador assembly

### üéØ Objetivo
Converter IR otimizado em **assembly MIPS-like**

### üîß Instru√ß√µes Geradas

```
ENTER                   ‚Üê Inicializa frame
LOAD R0, valor          ‚Üê Carrega valor em R0
STORE R0, vari√°vel      ‚Üê Armazena R0 em vari√°vel
ADD R0, R1              ‚Üê Soma R0 + R1 ‚Üí R0
SUB R0, R1              ‚Üê Subtrai R0 - R1 ‚Üí R0
MUL R0, R1              ‚Üê Multiplica R0 * R1 ‚Üí R0
SHL R0, n               ‚Üê Shift left (R0 << n)
PRINT R0                ‚Üê Imprime valor de R0
RET n                   ‚Üê Return com valor
LEAVE                   ‚Üê Limpa frame
RETURN                  ‚Üê Jump volta
```

### üìä Exemplo Real

```
ENTRADA (IR):
  resultado = 10
  print resultado
  return 0

ASSEMBLY GERADO:
main:
  ENTER
  LOAD R0, 10              ‚Üê Carrega 10 em R0
  STORE R0, resultado      ‚Üê Guarda em resultado
  PRINT R0                 ‚Üê Imprime 10
  RET 0                    ‚Üê Return 0
  LEAVE
  RETURN
```

---

## üß™ **TESTES**

### üìÅ Arquivos de Teste
```
tests/
‚îú‚îÄ‚îÄ alocation.txt         ‚Üê Aloca√ß√£o de mem√≥ria
‚îú‚îÄ‚îÄ code.txt              ‚Üê C√≥digo completo
‚îú‚îÄ‚îÄ conditional.txt       ‚Üê IF/ELSE
‚îú‚îÄ‚îÄ expressao_simples.txt ‚Üê Express√µes aritm√©ticas
‚îú‚îÄ‚îÄ function.txt          ‚Üê Fun√ß√µes
‚îú‚îÄ‚îÄ hello_world.txt       ‚Üê Hello world
‚îú‚îÄ‚îÄ loop.txt              ‚Üê Loops (WHILE, FOR)
‚îú‚îÄ‚îÄ rename.txt            ‚Üê Renomea√ß√£o de vari√°veis
‚îî‚îÄ‚îÄ simples.txt           ‚Üê C√≥digo simples
```

### üîß Como Rodar Testes

```bash
# Teste r√°pido
python test_final.py

# Compilar arquivo
python run.py -f tests/expressao_simples.txt

# Modo interativo
python run.py

# Com verbose
python run.py -f tests/code.txt --verbose

# Salvar assembly
python run.py -f tests/code.txt -o output.asm
```

### üìã Teste Exemplo

```python
from compiler import compile

codigo = """
int main() {
    int a = 7;
    int b = 8;
    int r = (a + b) * 2;
    return 0;
}
"""

result = compile(codigo, optimize=True, verbose=False)

if result['success']:
    print("‚úÖ Compila√ß√£o bem-sucedida!")
    print(f"  Tokens: {len(result['tokens'])}")
    print(f"  IR: {len(result['ir'].get_instructions())} instru√ß√µes")
    print(f"  IR Otimizado: {len(result['optimized_ir'].get_instructions())} instru√ß√µes")
    for linha in result['assembly']:
        print(linha)
```

---

## üìä **FLUXO COMPLETO**

```
C√≥digo Fonte (.py, .txt, .c)
    ‚Üì
[LEXER] ‚Üí Tokeniza√ß√£o
    ‚Üì TOKENS
[PARSER LL(1)] ‚Üí Parse Tree
    ‚Üì PARSE TREE
[AST BUILDER] ‚Üí AST
    ‚Üì AST
[SEMANTIC ANALYZER] ‚Üí Tabela S√≠mbolos
    ‚Üì VALIDADO
[IR GENERATOR] ‚Üí TAC/Qu√°druplas
    ‚Üì C√ìDIGO INTERMEDI√ÅRIO
[OPTIMIZER] ‚Üí CSE, CF, DCE, CP, Peephole
    ‚Üì IR OTIMIZADO
[CODEGEN] ‚Üí Assembly MIPS-like
    ‚Üì ASSEMBLY
[OUTPUT] ‚Üí Arquivo .asm ou console
```

---

## üîó **Integra√ß√£o de Componentes**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  compiler/main.py                       ‚îÇ
‚îÇ  (Orquestrador do pipeline completo)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì              ‚Üì              ‚Üì
    LEXER         PARSER            AST
  (lexer.py)   (parser.py)    (ast_builder.py)
        ‚Üì              ‚Üì              ‚Üì
    TOKENS       PARSE TREE         AST
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ SEMANTIC ANALYZER        ‚îÇ
            ‚îÇ (ast/analyzer.py)        ‚îÇ
            ‚îÇ + Symbol Table           ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ IR GENERATOR             ‚îÇ
            ‚îÇ (ir/ir_generator.py)     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
            TAC/QU√ÅDRUPLAS (IR)
                       ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ OPTIMIZER                ‚îÇ
            ‚îÇ (optimizer/optimizer.py) ‚îÇ
            ‚îÇ - CSE, CF, DCE, CP       ‚îÇ
            ‚îÇ - Peephole               ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
            IR OTIMIZADO
                       ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ CODE GENERATOR           ‚îÇ
            ‚îÇ (codegen/codegen.py)     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
            ASSEMBLY MIPS-like
                       ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ OUTPUT (run.py)          ‚îÇ
        ‚îÇ - Console                ‚îÇ
        ‚îÇ - Arquivo .asm           ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéì **Resumo dos T√≥picos Cr√≠ticos**

| T√≥pico | Criticidade | Por qu√™ |
|--------|-------------|---------|
| **Lexer** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Sem tokens, n√£o h√° parsing |
| **Parser LL(1)** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Gram√°tica √© a espinha dorsal |
| **AST** | ‚≠ê‚≠ê‚≠ê‚≠ê | Intermedi√°ria entre parse e sem√¢ntica |
| **An√°lise Sem√¢ntica** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Verifica validade do c√≥digo |
| **IR Generator** | ‚≠ê‚≠ê‚≠ê‚≠ê | Transforma em c√≥digo execut√°vel |
| **Optimizer** | ‚≠ê‚≠ê‚≠ê | Melhora efici√™ncia (opcional) |
| **Codegen** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Produz resultado final |
| **Testes** | ‚≠ê‚≠ê‚≠ê‚≠ê | Validam cada fase |

---

## üöÄ **Para Come√ßar**

1. **Entender Lexer** ‚Üí Tokens
2. **Entender Parser** ‚Üí Gram√°tica BNF
3. **Entender AST** ‚Üí Nodes
4. **Entender Sem√¢ntica** ‚Üí Valida√ß√£o
5. **Entender IR** ‚Üí Qu√°druplas
6. **Entender Otimiza√ß√µes** ‚Üí Redu√ß√£o
7. **Entender Codegen** ‚Üí Assembly
